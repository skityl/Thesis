% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Introduction} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter \ref{Introduction}. \emph{Introduction}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------

\section{Classical Infinitesimals}
According to the mathematicians of the 17th century, an ``infinitesimal"
is a quantity $x$ that is smaller than any positive magnitude. In other
words, for all $\varepsilon > 0$, 
\begin{equation}
\label{infCond}
    |x| < \varepsilon.
\end{equation}
Mathematicians manipulated infinitesimals
as though they were real numbers: addition, multiplication and division of infinitesimals
were permitted. 

Numerous definitions relied on the use of infinitesimals. For example,
a function $f:\Rl\rightarrow \Rl$ was said to be continuous at $x$
if $f(x+h)-f(x)$ is infinitesimal for all infinitesimals $h$.

Another example is that $f$ was said to be differentiable when the quantity
\begin{equation}
    \frac{df}{dx} := \frac{f(x+h)-f(x)}{h}
\end{equation}
exists for all infinitesimals $h$, and does not depend on $h$.

Mathematicians distinguished between infinitesimals of different ``sizes", 
and if $x$ is infinitesimal, then $x^2$ was said to be smaller than $x$,
and algebraic manipulations could be performed with ``sufficiently small
infinitesimals ignored".

However, as we are now aware, the condition in equation \ref{infCond} implies that $x = 0$, 
so all manipulations involving infinitesimals
are either trivial or impossible. Hence, the use 
of infinitesimals was banned from mathematics and their role
in analysis was replaced with the concept of a \emph{limit}.

Despite the difficulties with giving a non-contradictory definition
of infinitesimals, there are numerous reasons that the concept is appealing. 
Using infinitesimals makes some definitions in analysis seem simpler, for example
the above given definition of continuity. Infinitesimals
can also be more intuitive than limits. For these reasons, some mathematicians
have attempted to revive the concept of infinitesimals
by defining them in a rigorous manner. Most famously, one can 
use model theory to define and analyse a field of \emph{hyperreal numbers}
which strictly contains the real numbers, and includes a plentiful supply of infinitesimals.
This is called non-standard analysis, see \cite{robinson} for details.
Other approaches to rigorously definining infinitesimals include smooth infinitesimal
analysis, which is simply the observation that infinitesimals in the classical
sense are not self-contradictory objects if certain axioms of logic are ignored, see
\cite{sia} for an introduction to this approach.
A third approach is the Levi-Civita field \cite{lcf}.

A comprehensive history of the use of infinitesimals prior to the 19th
century is \cite{infinitesimalBook}.

\section{Compact Operators as Infinitesimals}
A relatively new approach to rigorously defining infinitesimals
comes from non-commutative geometry. In this setting, all objects
of interest such as functions, vector fields, differential forms, etc., are
thought of as operators on a Hilbert space. 

In what follows, let $\Hilb$ be a complex separable Hilbert space. 

Suppose we wish to find a good definition
of an ``infinitesimal operator" on $\Hilb$. A preliminary definition
would be to say that an operator $T$ is infinitesimal if for every $\varepsilon > 0$, 
\begin{equation}
    \|T\| < \varepsilon.
\end{equation}  
This definition is useless, as it implies that $T = 0$. However, we can get something close:
\begin{definition}
\label{infinitesimal}
    Let $T \in \mathcal{B}(\Hilb)$. We say that $T$ is \emph{infinitesimal}
    if for every $\varepsilon > 0$, there is a finite dimensional
    subspace $E$ such that
    \begin{equation}
        \|T|_{E^\perp}\| < \varepsilon.
    \end{equation}
    (here $T|_{E^\perp}$ denotes the restriction of $T$ to the orthogonal complement of $E$.)
\end{definition}

\begin{remark}
    Recall that the ideal of compact operators $\mathcal{K}(\Hilb) \subseteq \mathcal{B}(\Hilb)$
    is the closure of the set of finite rank operators. It is easy to see that $T$
    is infinitesimal (in the sense of definition \ref{infinitesimal}) if and only
    if $T$ is compact.
\end{remark}

We require a way of measuring the ``size" of an infinitesimal. According to
definition \ref{infinitesimal}, an infinitesimal is ``zero modulo finite dimensional
subspaces", and it is sensible to consider the ``size" of the infinitesimal
as being measured by the speed at which the dimension of the subspaces $E$
must increase as $\varepsilon$ moves towards zero. To this end, we define
the singular values.
\begin{definition}
    Let $T \in \mathcal{B}(\Hilb)$, and $n \geq 0$. Define
    \begin{equation}
        \mu_n(T) := \inf\{\|T-F\|\;:\;\operatorname{rank}(F) \leq n\}.
    \end{equation}
    Then $\mu_n(T)$ is called the $n$th singular value of $T$, and the sequence
    $\{\mu_n(T)\}_{n=0}^\infty$ is called the sequence of singular values. 
\end{definition}

\begin{remark}
    For any operator $T$, the sequence $\{\mu_n(T)\}_{n=0}^\infty$
    is strictly non-increasing.
    If $T$ is compact, the sequence of singular values of $T$
    is decreasing and approaches $0$.
\end{remark}

We shall regard the \emph{size} of $T$ as being given by the \emph{rate of decay}
of $\{\mu_n(T)\}_{n=0}^\infty$. 


\section{Expected Properties of infinitesimals}
According to $17$th century mathematicians, infinitesimals were supposed
to have a number of remarkable properties:
\begin{enumerate}
    \item{} There exist non-zero infinitesimals.
    \item{} Infinitesimals can be added, subtracted, multiplied and divided
    just like real numbers.
    \item{} A real number multiplied by an infinitesimal produces an infinitesimal.
    \item{} Infinitesimals can be split into ``sizes", and we can work modulo
    a particular size of infinitesimal.
    \item{} If $x$ is an infinitesimal, then $x^2$ is a smaller infinitesimal.
    \item{} Given a function $f:\Rl\rightarrow\Rl$, there is a function $df$
    representing the infinitesimal variation in $f$, that is $df(x) = f(x+\delta)-f(x)$
    for some fixed infinitesimal $\delta$.
    \item{} If a function $f$ is smoother than a function $g$, then $df$ is smaller
    than $dg$.
    \item{} If $f$ is a smooth function of $x$, we can write
    \begin{equation}
        df = f'(x)dx
    \end{equation}
    provided that sufficiently small infinitesimals are ignored.
\end{enumerate}

If we interpret compact operators as infinitesimals, we see that analogues of these statements
remain true:
\begin{enumerate}
    \item{} There indeed exist non-zero compact operators.
    \item{} Compact operators can be added and subtracted like numbers, they can
    also be multiplied (although multiplication is not commutative). We cannot
    divide by a compact operator on an infinite dimensional Hilbert space. However
    it is true that if $XT = YT$ for operators $X,Y \in \mathcal{B}(\Hilb)$ for all
    $T \in \mathcal{K}(\Hilb)$, then $X = Y$.
    \item{} $\mathcal{K}(\Hilb)$ forms an ideal of $\mathcal{B}(\Hilb)$, so a bounded
    operator multiplied by a compact operator produces a compact operator.
    \item{} We can measure the size of a compact operator
    by the rate of decay of its sequence of singular values.
\end{enumerate}
For item $5$, we need the following lemma,
\begin{lemma}
    Let $T \in \mathcal{K}(\Hilb)$. Then for $n\geq 0$,
    \begin{equation}
        \mu_n(T^2) \leq \|T\|\mu_n(T).
    \end{equation}
\end{lemma}
\begin{proof}
    By definition,
    \begin{equation}
        \mu_n(T^2) = \inf\{\|T^2-F\|\;:\; \operatorname{rank}(F) \leq n\}.
    \end{equation}
    Since if $F$ has rank $n$, $TF$ has rank not exceeding $n$, we have
    \begin{align}
        \mu_n(T^2) &\leq \inf\{\|T^2-TF\|\;:\;\operatorname{rank}(F) \leq n\}\\
                   &\leq \inf\{\|T\|\|T-F\|\;:\;\operatorname{rank}(F) \leq n\}\\
                   &= \|T\|\mu_n(T).
    \end{align}
\end{proof}
Hence we have property $5$: if $T$ is infinitesimal, then the singular values
of $T^2$ decay more rapidly than those of $T$. 

Now for properties $6$, $7$ and $8$, we need a way of defining $df$. This is precisely
the role played by the quantised differential.

\section{Quantised Differentials}
The following definition may at first glance seem strange and unmotivated,
\begin{definition}
    Consider the operator $\D = \frac{1}{i}\frac{d}{dx}$ of differentiation
    on $\Rl$ (or $\D = \frac{1}{2\pi i}\frac{d}{d\theta}$ on $\Circ$). By the Borel functional calculus, we can define $F := \sgn(\D)$. 
    $F$ is called the Hilbert transform. For a function $f \in L^1(\Rl)$ (resp. $f \in L^1(\Circ)$)
    we have the pointwise multiplication
    operator $M_f$ considered as an operator on $L^2(\Rl)$ (resp. $L^2(\Circ)$), $M_f$
    may be a densely defined unbounded operator when $f \notin L^\infty(\Rl)$ 
    (resp. $f \notin L^\infty(\Circ)$).
    
    The operator
    \begin{equation}
        \qd f := [F,M_f]
    \end{equation}
    is an operator on $L^2(\Rl)$ (resp. $L^2(\Circ)$)
    called the \emph{quantised differential} of $f$.
\end{definition}

$\qd f$ is supposed to play the role of $df$ in $17$th century analysis. 
We use the symbol $\qd f$ instead of $df$ since in modern mathematics the symbol $df$
is often used to denote the exterior differential of $f$. It must be emphasised
that the exterior differential $df$ and the quantised differential $\qd f$ are very different objects.
The difference between $df$ and $\qd f$ will be explained in detail in Chapter \ref{AbstractDifferentialAlgebra}.

Similar to the case of functions $f:\Rl\rightarrow \Cplx$, we can also
study functions on the circle. Let
\begin{equation}
    \Circ := \{z \in \Cplx\;:\;|z| = 1\}.
\end{equation}

Then we have a differentiation operator 
\begin{equation}
    \D := \frac{1}{2\pi i} \frac{d}{d\theta},
\end{equation}
and $F := \sgn(\D)$. Then we can define quantised
differentials $\qd f := [F,M_f]$. 

\begin{remark}
    We have chosen to call the quantity $[F,M_f]$
    a quantised differential, and to denote it $\qd f$. 
    
    This terminology is not universal. In particular, the book \cite{Connes94}
    calls $[F,M_f]$ a quantised derivative and denotes it $df$. 
    
    We shall use the notation $\qd f$ to prevent confusion with the exterior
    derivative $df$, and we call it a differential to be consistent
    with the idea of an ``infinitesimal increment".
\end{remark}    

It is not easy to motivate the definition $\qd f := [F,M_f]$. Instead,
we shall show that $\qd f$ satisfies all the properties
anticipated for a differential. 

The two questions that we shall attempt to answer are as follows:
\begin{enumerate}
    \item{} In what sense is it true that if $f$ is smoother than $g$, then $\qd f$
    is smaller than $\qd g$? This will be answered in Chapter \ref{IdealMembership}.
    \item{} In what sense is it true that if $\varphi$ is a function that is smooth
    on the range of a function $f$, then $\qd \varphi(f) = \varphi'(f)\qd f$? This
    will be answered in Chapter \ref{TheChainRule}.
\end{enumerate}

In order to answer those questions, it is informative to give an explanation
of the origin of the defintion of $\qd f$. 

\section{Non-commutative geometry}

\subsection{Introduction to the non-commutative world}
Non-commutative geometry is a relatively new topic in mathematics. Non-commutative
geometry is best thought of not as a collection of results, but instead as a
perspective on mathematics. 

It is difficult to give a completely satisfying general definition of non-commutative geometry, but 
one can say that non-commutative geometry is the study of non-commutative algebras
which are somehow similar to algebras of functions on geometric spaces, using
the methods and language of geometry.

The key idea which underlies most of non-commutative geometry is the duality
between geometric spaces and algebras. 

\begin{example}
    Let $X$ be a compact Hausdorff space. Let $C(X)$ be the algebra
    of continuous complex valued functions on $X$. $C(X)$ naturally carries
    the structure of a commutative unital $C^*$-algebra. In fact, for any commutative
    unital $C^*$-algebra $\A$, there is a compact Hausdorff space $K$
    such that $\A$ is isometrically $*$-isomorphic to $C(K)$.
    
    Given a continuous function $f:X\rightarrow Y$ between compact Hausdorff spaces
    $X$ and $Y$, there is a pull-back function $f_*:C(Y)\rightarrow C(X)$ defined
    by $f_*(h) = h\circ f$ for $h \in C(Y)$. Since ${\id_X}_* = \id_{C(X)}$, 
    and $(f\circ g)_* = g_* \circ f_*$, the mapping $X\mapsto C(X)$
    is a functor. 
    
    Let $\mathbf{CHTop}$ be the category of compact Hausdorff spaces
    with morphisms as continuous functions, and let $\mathbf{CUC^*Alg}$
    be the category of commutative unital $C^*$-algebras with morphisms
    as continuous $*$-algebra homomorphisms.
    
    Thus we have a contravariant functor,
    \begin{equation}
        C:\mathbf{CHTop}\rightarrow \mathbf{CUC^*Alg}.
    \end{equation}
    This effects an equivalence of categories,
    \begin{equation}
        \mathbf{CUC^*Alg} \isom \mathbf{CHTop}^{Op}.
    \end{equation}
    
    Let $\mathbf{UC^*Alg}$ be the category of unital $C^*$-algebras,
    which are not necessarily commutative. Inspired by the duality between commutative
    unital $C^*$-algebras and compact Hausdorff spaces, we define
    the category of (potentially) non-commutative compact Hausdorff spaces
    to be $\mathbf{UC^*Alg}^{Op}$.
\end{example}

\subsection{A brief introduction to Quantum Mechanics}
Non-commutative geometry can be thought of simply as the study of non-commutative
algebras using geometric language. However, much research in non-commutative
geometry is inspired by quantum mechanics. It is therefore instructive to 
give a brief description of quantum mechanics. 


\begin{definition}
    A \emph{quantum mechanical system} is a pair $(\A,\Hilb)$ where $\Hilb$
    is a complex separable Hilbert space and $\A$ is a $*$-algebra
    of (possibly densely defined and unbounded) operators on $\Hilb$. 
    Denote the inner product on $\Hilb$ by $(\cdot,\cdot)$
    and $\|\psi\|^2 := (\psi,\psi)$.
    
    
    A self-adjoint element of $\A$ is called an \emph{observable}. 
    The elements of $\Hilb$ are called \emph{states}. 
    
    Typically, we identify together elements of $\Hilb$
    which differ by a nonzero scale factor, and the element $0 \in \Hilb$
    is ignored entirely. So technically we work over the \emph{projective
    Hilbert space} $\mathbb{P}\Hilb$.
    
    To specify \emph{the state of the system} $(\A,\Hilb)$ is the same
    as specifying some $\psi \in \Hilb$.
\end{definition}

We think of $(\A,\Hilb)$ as encoding a physical system. 
Typically we think of an observable as a measurable
property of a system. The states correspond to potential
configurations of the system.

Given an observable $A$, the potential range
of values that can be measured
for the corresponding physical quantity is the spectrum $\sigma(A)$. Unlike in classical mechanics,
quantum mechanics can only make predictions that are probabilistic.
The second difference to classical mechanics is that the act of observation changes
the state of the system.

The link
between $\sigma(A)$ and $A$ is provided by the spectral theorem, [CITE]
\begin{theorem}[The Spectral Theorem]
    Let $(\A,\Hilb)$ be a quantum mechanical system. Let $A \in \A$ be an observable.
    Then there is a projection valued measure $E_A$ on $\sigma(A)$ such that
    \begin{equation*}
        A = \int_{\sigma(A)} \lambda\;dE_A(\lambda).
    \end{equation*}
\end{theorem}

Using the spectral theorem, we may state our first postulate.
\begin{postulate}
\label{pos1}
    Let $(\A,\Hilb)$ be a quantum mechanical system, in a state $\psi$. 
    
    Let $A \in \A$ be an observable, with associated spectral measure $E_A$. 
    
    For some Borel set $\Delta \subseteq \sigma(A)$, the probability 
    that the observed value of $A$ lies in $\Delta$ is given by
    \begin{equation*}
        P_A(\Delta;\psi) := \frac{(\psi,E_A(\Delta)\psi)}{\|\psi\|^2} = \frac{\|E_A(\Delta)\psi\|^2}{\|\psi\|^2}.
    \end{equation*}
    (Note that this is the same for any scalar multiple of $\psi$, and is undefined
    for $\psi = 0$.)
    
    Suppose that $A$ is now observed, and the value is known to lie
    in the set $\Delta \subseteq \sigma(A)$. Then the state
    of the system changes to
    \begin{equation*}
        \frac{E_A(\Delta)\psi}{\|E_A(\Delta)\psi\|}.
    \end{equation*}
\end{postulate}

\begin{remark}
    There are two extraordinary features of this postulate.
    \begin{enumerate}
        \item{} The state of the system changes upon observation.
        \item{} The order of observation is important, since
        for any observables $A$ and $B$, and $\Sigma \times \Delta \subseteq \sigma(A)\times\sigma(B)$, 
        in general,
        \begin{equation*}
            \frac{E_A(\Sigma)E_B(\Delta)\psi}{\|E_A(\Sigma)E_B(\Delta)\psi\|} \neq \frac{E_B(\Delta)E_A(\Sigma)\psi}{\|E_B(\Delta)E_A(\Sigma)\psi\|}.
        \end{equation*}
    \end{enumerate}
\end{remark}

\begin{remark}
    This discussion of quantum mechanics is far from comprehensive. The 
    treatment here is based on \ref{qm1}, and the text \ref{qm2}
    goes into further detail on this topic.
\end{remark}


%\begin{theorem}
%    Let $(\A,\Hilb)$ be a quantum mechanical system
%    which has state $\psi$. If $A \in \A$
%    is an observable, then the expected value of the observed
%    value of $A$ is 
%    \begin{equation*}
%        E(A;\psi) = \frac{(\psi,A\psi)}{\|\psi\|^2}
%    \end{equation*}
%\end{theorem}
%\begin{proof}
%    First consider the case when $A$ is positive. Then $\sigma(A) \subseteq [0,\infty)$,
%    and 
%    \begin{equation*}
%        E(A;\psi) := \int_{\sigma(A)} \lambda\;dP_A(\lambda;\psi).
%    \end{equation*}
%    By the monotone convergence theorem, this is
%    \begin{equation*}
%        E(A;\psi) = \lim_{n\rightarrow\infty} \sum_{k=0}^{2^{2n}} \frac{k}{2^n}P_A\left(\left[\frac{k}{2^n},\frac{k+1}{2^n}\right);\psi\right).
%    \end{equation*}
%    Now we use the definition of $P_A$ in postulate \ref{pos1}:
%    \begin{align*}
%        E(A;\psi) &= \lim_{n\rightarrow\infty} \sum_{k=0}^{2^{2n}} \frac{k}{2^n}\frac{\left(\psi,E_A\left(\left[\frac{k}{2^n},\frac{k+1}{2^n}\right)\right)\psi\right)}{\|\psi\|^2}\\
%        &= \frac{1}{\|\psi\|^2}\left(\psi,\lim_{n\rightarrow\infty} \left(\sum_{k=0}^{2^{2n}} \frac{k}{2^n}E_A\left(\left[\frac{k}{2^n},\frac{k+1}{2^n}\right)\right)\right)\psi\right).
%    \end{align*}
    
%    Now, using $A = \int_{\sigma(A)} \lambda\;dE_A(\lambda)$, we get
%    \begin{equation*}
%        E(A;\psi) = \frac{(\psi,A\psi)}{\|\psi\|^2}.
%    \end{equation*}
%    
%    This completes the proof for $A \geq 0$. For general $A$,
%    express $A$ as a difference of two positive operators.
%\end{proof}

\subsection{Non-commutative spaces}
Inspired by quantum mechanics, quantum mechanics can be thought
of as the study of spaces with coordinates such that the order of observation
of coordinates is important. 

Accordingly, a general non-commutative space can be defined
as a pair $(\A,\Hilb)$, just as a quantum mechanical system.
The elements of $\A$ are ``coordinate functions", and their
action on the elements of $\Hilb$ quantifies how the ``geometry"
changes under observation.


